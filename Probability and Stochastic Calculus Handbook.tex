\documentclass[11pt, openany]{book}              % Book class in 11 points
\parindent0pt  \parskip10pt             % make block paragraphs
\raggedright                            % do not right justify

% user used package




\title{\bf Probability and Stochastic Calculus Handbook}    % Supply information
\author{Xinhe Liu}              %   for the title page.
\date{2018-2-28}                           %   Use current date. 

% Note that book class by default is formatted to be printed back-to-back.
\begin{document}                        % End of preamble, start of text.
% \frontmatter                            % only in book class (roman page #s)
\maketitle                              % Print title page.
\tableofcontents                        % Print table of contents
\mainmatter                             % only in book class (arabic page #s)


\part{Measure and Probability}
\chapter{Probability}                % Print a "chapter" heading

\section{Probability Model}

\begin{enumerate}
	\item \textbf{Sample space}($\Omega$), the collection of all possible outcomes of an experiment
	\item \textbf{Events} (a subset of $Omega$) or $\mathcal{F}$ sigma-algebra.
	\item \textbf{Probability measure} (P) assigns probabilities to elements of $\mathcal{F}$. P must satisfy:
	\begin{enumerate}
		\item Nested $P(A) \geq 0$ for $ \forall A \in \mathcal{F}$
		\item $P(\Omega) = 1$ 
		\item $P(\bigcup_{i = 1}^\infty A_i) = \sum_{i = 1}^\infty P(A_i)$ for adjoint events($A_i \bigcap A_j = \emptyset, i \neq j$).
	\end{enumerate}
\end{enumerate}

\textbf{Corollary}

\begin{enumerate}
		\item $P(A) + P(A^C) = 1$
		\item %$P(\Omega) = 1$ 
		\item %$P(\bigcup_{i = 1}^\infty A_i) = \sum_{i = 1}^\infty P(A_i)$ for adjoint events($A_i \bigcap A_j = \emptyset, i \neq j$).
	\end{enumerate}

\subsection*{Inclusion-exclusion principle}
$$\left| \bigcup_{i=1}^n A_i \right|= \sum_{k = 1}^n (-1)^{k+1} (\sum_{1\leq i_1 ... \leq i_k}) \left| A_{i_1}\cap...\cap A_{i_k}\right|$$

$(\Omega, \mathcal{F}, P)$ is the \textbf{probability space}.

\section{Conditional Probability}

$$P(A | B ) = \frac{P(A \cap B)}{P(B)} $$
Law of Total Probability
$$ P(A) = \sum_i^n P(A|B_i)P(B_i)$$
Bayes Theorem
$$P(A | B ) = \frac{P(A|B_i)P(B_i)}{\sum_j^n P(A|B_i)P(B_i)} $$

\section{Independence}

A and B are independent if

$$P(A \cap B) = P(A) P(B)$$ or
$$E(f(A) g(B)) = E(f(A)) E(g(B), \forall f,g$$

$A_{i_1}, ... A_{i_n}$ is independent if for \textbf{every collection} ${i_1, i_2,...i_n}$ we have

$$P(\bigcup_{i=1}^n A_{i_k}) = \prod_{j=1}^k A_{i_j}$$

Conditional Independence:
$$P(A \cap B |C) = P(A|C) P(B|C)$$
$$ $$

\section{Random Variable}

A Random Variable is a function assign a real-number to a event
$$X:\Omega \to X$$

A random variable is measurable if $\{\omega : X(\omega) \leq c\} \in \mathcal{F} , \forall c$

C.D.F is a function satisfies
\begin{enumerate}
	\item $F_X(c)$ is nondecreasing on c
	\item $\lim_{c \to \infty} F_X(c)=1$
	\item $\lim_{c \to -\infty} F_X(c)=0$
	\item \textbf{right-continous} : $\lim_{y \to c} F_X(y)=F_X(c)$
	\item $P(X >c) = 1-F_X(c)$
	\item $P(X = c) = F_X(c)-\lim_{y \to c} F_X(y)$
	\item $P(a < X \leq b) = F_X(b)-F_X(a)$
\end{enumerate}

p.d.f satisfies 
\begin{enumerate}
	\item $f_X(x) > 0$ 
	\item $ \int_{-\infty}^{\infty}f_X(u)du=1$
	\item $ \int_{a}^{b}f_X(u)du=P(a \leq X \leq b)$
	\item $ \int_{-\infty}^{\infty}u f_X(u)du=E(X)$
\end{enumerate}

\subsection{Expectation}

$$E(X) = \sum k f_X(k)$$ (probability mass function)

For continuous RV, we need$ \int_{0}^{\infty}f_X(u)du < \infty$ or $ \int_{-\infty}^0   f_X(u)du> \infty$

\textbf{Theorem}

$$ E(h(X)) = \sum h(k) f_X(k)$$
$$ E(g(X)) = \int_{-\infty}^{\infty} g(u) f_X(u)du$$
$$$$
$$$$
$$$$
$$$$
$$$$
$$$$
$$$$
$$$$
$$$$

\section{Things to Remember}
Discrete Distributions
\begin{enumerate}
	\item Bernoulli(p) Distribution
	$$ E(X) = p, V(X) = p(1-p)$$
	\item Binomial(n,p) Distribution
	 $$ f_X(k) = {N \choose k} p_k (1-p)^{n-k}, E(X) = np, V(X) = np(1-p) $$
	\item Geometric(p) Distribution - X is the trial prior to success
	$$ f_X(k) =  p (1-p)^k, E(X) = (1-p)p , V(X) = (1-p)/p^2$$
	\item Possion($\lambda$) Distribution - counts in a period of time
    $$ f_X(k) =  \frac{e^{-\lambda}\lambda^k}{k!}, E(X) = \lambda, V(X) = \lambda $$
	\item 	\item 	\item  
\end{enumerate}
Continuous Distributions
\begin{enumerate}
	\item Bernoulli(p) Distribution
	$$ E(X) = p, V(X) = p(1-p)$$
	\item Binomial(n,p) Distribution
	 $$ f_X(k) = {N \choose k} p_k (1-p)^{n-k}, E(X) = np, V(X) = np(1-p) $$
	\item Geometric(p) Distribution - X is the trial prior to success
	$$ f_X(k) =  p (1-p)^k, E(X) = (1-p)p , V(X) = (1-p)/p^2$$
	\item Possion($\lambda$) Distribution - counts in a period of time
    $$ f_X(k) =  \frac{e^{-\lambda}\lambda^k}{k!}, E(X) = \lambda, V(X) = \lambda $$
    $X + Y \sim Poisson(\lambda_1 + \lambda_2)$
	\item 	\item 	\item  
\end{enumerate}

Poisson Process

\section{Practices}

\begin{enumerate}
	\item Card Game
	\begin{enumerate}
		\item 2 kings from 52 cards : use Combination or conditional probability (step)
		\item your second card is a King: use LFTP 
		\item * water, earth, wind, fire : win of water and earth, lose if fire (Hint: wind is irrelevant here)
	\end{enumerate}
	\item Dice Game 
	 \begin{enumerate}
		\item sum of two dices are seven
	  \end{enumerate}	
	 \item Coin Game
	 \item Triangle* : probability of forming a triangle by two breaks on a length-1 stick\\
	 \begin{itemize}
	 	\item Way1: calcualte the opposite - one piece longer than 0.5 and use Inclusion–exclusion principle
	 	\item Way2: 
	 \end{itemize}
     \item  Monty Hall* - Bayes
     \item Can different random variables have the same distribution? \\ yes! eg.) flipping coin twice: 1 for each head, -3 for two tails v.s. 1 for different, 2 for 2 heads, 3 for two tails
     \item Can expectation be infinity? \\ Yes! \textbf{Zeta Distribution}
     \item Can expectation be not existed? \\ Yes! \textbf{Chauchy Distribution}
     \item The average number of claims in one year is 0.6, what's the probability of more than one claim (Poisson)
\end{enumerate}

\chapter{Chapter Two}
Stochastic Process
M
1. easure-based probability1.1 Prob Space- $\Omega$(sample space), P(prob measure), F(sigma-algebra)Sigma Algebrainfinite (all inclusive) sigma-algebra**Kolmogorov Extension TheoremBorel SetsMeasure – Countabily additive functionsLebesgue MeasureProbability Measure
1.2 Expectation
1. Measurability  
2. Partial Averaging Lebesgue Integral properties: discrete form, comparison, linearity, Jensen’s Inequality Random Variable (F measurable random variables) sigma algebra generated by R.V. distribution/ distribution measure/ density  
1.3 Independence
Probability definition, sigma-algebra definition
expectation definition
1.4 Conditional Expectation
A f-measurable random variable satisfies partial averaging identity
$$int_F E(Xf) dp = int_F Xdx$$
Conditional Probabilities
A F-measurable random variable, integral upto interaction probability
$$int_F P(A_i| f) = P(A_i and F)$$
Randon-Nikodym Theorem
Properties
1. Linearity 2 Taking out what is know 3 iterated conditioning  
2. independence property (like no information) 5. Jensen’s Inequality  
1.5 Filtration and adapted process
Filtration generated by X ( family of sigma algebras)
Adapted Process (X(t) is t-measurable)

1.6 Martingale \& Markov Process
Martingale
Stopping Times (function that the event is in filtration)
Dobb’s Optional Sampling Theorem
Markov Process
Super martingale, Sub martingale
1. Browian Motion Symmetric Random Walk Variance, Expectation, First Variation (use Mean-Value Theorem when it is differentiable) Quadratic Variation (Attention: it is a Sum) Brownian Motion continuous Stationary Independent increment, normal increments, variation Levy’s Theorem (Levy’s Criterion)  
2. Ito Integral Martingale Property Ito Isometry Quadratic Variation Ito-Doubelin formula Browian filtration F(s)< F(t), Browian motion measurable at time t. Martingles 
3. Black-Scholes  
4. Multi-dimensional  
Joint Quadratic Variation
Multi-dimensional Ito’s Formula
Multi-dimensional Browian Motion
Multi-Dimensional Levy’s Theorem
One-dimensional, multi-dimensional
1. Risk-Neutral Pricing  
Random-Nikoym Theorem
Girsanov Theorem
Martingale Representation Theorem
Futures and Forward
1. Relationship with P.D.E  
Transition Density
Markov Process / Markov Property
Feynman - Kac Theorem
Kolmogrov Forward Equation
Kolmogrov Backward Equation
Dupire’s Equation - Volatility
Delta Hedge
under different rates
with dividend (rate q


\part{Stochastic Calculus}

\chapter{Brownian Motion and Martingale}

Browian Motion
Levy’s Theorem

Reflection Principle

Prove the Martingales listed above (drift = 0)
valuation

\chapter{Ito's Lemma and Black-Scholes}


varaince swap

swaptoion

barrier options

quanto, exchange options

chooser, cap, forward-start option

What is transition density? Transition density of BM/GBM?

p (t,x,T,y)

Derive Kolmogorov Backward Equation/ Kolmogorov Forward Equation?

Derive Dupire’s Equation.

$$c_k = e^{-rt} P(S_t >K) c_{kk} = e^{-rt} p(0,S_0,T,K)$$

Martingale? Exponential Martingale? (- Moment Generating Functions) Quadratic Variation?

Derive B-S P.D.E

Delta Hedge with futures/ options/ other instruments?

Self-financing condition?

Hedging Portfolio with Multiple Rates/ Collaterals

Stochastic Vol/ Interest Rate P.D.E

Asian Option/ Corridor Option (path dependent option) P.D.E

Derive B-S formula - Risk Neutral Pricing

%One Stock Option: h(S_T) as payoff ( eg. $$S_T^2, ln(S_T), 1/(S_T)$$ )
%
Two Stock Options: Spread option: max(S1- S2,0)

Futures and Forward

derive Futures price (prove it is a martingale)

derive forward price

Forward and Futures Spread ( negatively correlated underlying and discount process, futures> forward

\chapter{Asset Pricing Theory}

No Arbitrage pricing 
	e.g. forward exchange rate 
	put-call parity 

Risk neutral probability 
	e.g. Binomial model

State Price
	Arrow-Debreu securities

%Fundamental Theorem of Asset Pricing I and II 
%	I. NO Arbitrage $\LeftrightArrow$ $\widetilde{P}$ exist Attention: $RNP > 0$ 
%	II. market is complete (every security can be replicated ) $\LeftrightArrow %\norm{\widetilde{P}} = 1 (!\widetilde{P})$ 

Adapted Process 
	$$( X(\omega) = X(\omega_n, …,\omega_1) )$$ - known $\omega$ at time n)

State Process
    $$Y_{n+1}= f(Y_n, omega_n+1)$$ (can be multidimensional)
   Theorem
      $$r_n = g_n(Y_n)$$ for some $g_n$ 
      $Y_n$ is markov -> 
		then $Y_n$ is a state process

Stoping Time
    1. $\tau \in {1,2,…N}$
    2. $\tau(\omega)< n$ is determined by ($omega_1, omega_2, omega_n$)  ($F_n$ measurable) 


Martingale
   Theorem (proof- indicator function and tower property) - optional sampling 
        martingale stopped at stopping time is also a martingale $E(x_\tau) = X_0 $

Markov Process
   $f_n(Y_n) = E_n(f_m(Y_m))$
    for some $f_n = f_n(y), n \leq m$

  Theorem $Y_{n+1} = g_{n+1} (X_{n+1}, Y_n）$for some $g_n, X_n$ be IRVs and $Y_n$ are adapted - then Y is a markov process

$F_n$ independence
	X and all $F_n$ measurable $Z_n $are independent

Supermartingale and Submartingale
      $E(X_n+1) \leq X_n$ supermartingale
      Theorem Doob’s decomposition (use to prove optional sampling)
         $$X_n = M_n - A_n$$

Fundamental Theorem of Optimal Investment (one-period)
   $$U‘（\hat{X_1}) = \lambda \frac{\widetilde{P}}{P}$$







Multiperiod-Asset Pricing problems

  Barrier Options
   up-and-in call
	1. state process - $M_n, S_n n^2$ computation
         2. state process $-Z_n = 1{M_n > u}, S_n  2(n+1)$

   Asian Option
       1. state process $A_n, S_n$ solve 2-dimensional P.D.E.
       2. state process $Z_n = A_n/S_n, S_n$ solve 1-dimensional P.D.E. ($f_N = S max( A/S - 1)$ ) 


   Think conditional(stopping time)
    Down-and-Rebate Option
      use indicator function 1{down} + 1{up} (Value to Continue)
    American Options max(value to continue, intrinsic value) 



pricing models

Binomial model 
calibrate 
 match vol crr 


other staff
independence 
$$E(f(x) g(y)) =  E(f(x)) E(g(y)) \forall f,g$$
OR
$$P( X ) P( Y ) = P(X Y)$$



Markov Process not martingale
   non constant sequence of real numbers

Martingale not markov
    $$X_0 = 0, X_1 = \epsilon)1$$
    $$X_n = \epsilon_1 ( 1+ \epsilon_2 +…+ \epsilon_n)$$



\chapter{S.D.E and P.D.E}

Martingale - SDE 

connected by —— change of variables 

Markov- PDE


Standard S.D.E
Solve GBM

Solve O-U process ( Vasicek model)

\chapter{Fixed Income}

interest rate futures, forward interest rate
Forward LIBOR

Derive HJM condition

\chapter{Change of Measure and Foreign Exchange}


\section{ Tricks}

做题技巧

Tower Property

For(t,t) = St , f(t,t) = Rt ( the underlying asset price)

Change Measure A-B-C by Zt = *numeraire B/ Numeraire A (with normalization)

凑 exponential martingale， 凑Black - Scholes Form/ Black’s Form

MGF (构造)

做差

Conditional Expectation- Tower Property

Ito’s Formula

Important Martingales

$$M^2- [M,M]_t$$

$$MN - [M,N]$$

$$exp (M^2 - [M,M]t/2)$$

$$Ito f - \int_0^t ( df/dt +d^2f/dx^2)$$

Martingale stopped at stopping time

概率：构造partition， patrial averaging

正态： decomposition

martingale ： 作差


(explain) Change of Measure- Change of Numeraire- Girsanov Theorem (Change Drift)

Foreign Exchange

Change of Measure - foreign exchange measure, foreign exchange measure

price a Quanto
 
\section{A Subheading}                  % Print a "section" heading
The following sectioning commands are available:
\begin{quote}                           % The following text will be
 part \\                                %    set off and indented.
 chapter \\                             % \\ forces a new line
 section \\ 
 subsection \\ 
 subsubsection \\ 
 paragraph \\ 
 subparagraph 
\end{quote}                             % End of indented text
But note that---unlike the \texttt{book} and \texttt{report} classes---the
\texttt{article} class does not have a ``chapter" command.
 
\end{document}                          % The required last line 